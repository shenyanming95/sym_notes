# 1.理论

## 1.1.内存条

内存，也叫DRAM，即动态随机存储器。本质上它就是下图所示的条型组件：

![](https://static001.geekbang.org/resource/image/0d/8e/0d0d85383416f2f8841aeebe7021a88e.jpg?wh=3541*1553)

在 PCB 板上有内存颗粒芯片，主要是用来存放数据的。SPD 芯片用于存放内存自身的容量、频率、厂商等信息。还有最显眼的金手指，用于连接数据总线和地址总线，电源等。

内存储存颗粒芯片中的存储单元是由电容和相关元件做成的，电容存储电荷的多、少代表数字信号 0 和 1。而随着时间的流逝，电容存在漏电现象，这导致电荷不足，就会让存储单元的数据出错，所以 DRAM 需要周期性刷新，以保持电荷状态。因此内存需要不断地供电。

**逻辑上我们只需要把内存看成一个巨大的字节数组就可以，而内存地址就是这个数组的下标**。

## 1.2.局部性原理

局部性原理：在程序的执行过程中，数据和指令的访问往往具有局部集中的特点。主要包括以下两个方面：

1. 时间局部性（Temporal Locality）：时间局部性指的是程序在一段时间内对某个数据或指令的多次访问。当程序执行一条指令或者访问一个数据时，很可能在近期的某个时间点再次访问同样的指令或数据。这是因为在程序中，往往会有循环结构、重复的子程序调用等，导致某些数据和指令在短时间内被多次使用。
2. 空间局部性（Spatial Locality）：空间局部性指的是程序在一段时间内访问的数据或指令在空间上彼此相邻。当程序访问某个数据或指令时，它很可能会在附近的内存位置访问其他相关的数据或指令。这是因为程序的数据和指令通常以连续的块或者相邻的存储位置进行存储，因此对一个数据或指令的访问往往会引起对附近数据或指令的访问。

通过这个原理可得到一个结论：无论一个进程占用的内存资源有多大，在任一时刻，它需要的物理内存都是很少的

# 2.虚拟内存

计算机运行的所有数据都会落到物理内存里，在早期的CPU指令集里，从内存加载数据、向内存写入数据都是直接操作物理内存。在嵌入式设备中，这种操作是正常的，毕竟嵌入式设备正常只有一个应用在执行；但是在多任务的操作系统中，进程直接操作物理内存，容易出错和冲突，因此设计了虚拟内存。

每个进程拥有独立且隔离的虚拟内存，进程可以将数据存放到虚拟内存中，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存。

![](https://static001.geekbang.org/resource/image/4b/48/4bae735761c77bd0efa26974c8f53548.jpg?wh=2284x1238)

1. 虚拟内存虽然提供了很大的空间，但进程启动后，这些空间并不是全部都能使用，还是需要显式调用malloc等内存分配接口才能将内存从『待分配』状态变成『已分配』
2. 分配得到一块虚拟内存后，它属于『未映射』状态，此时它并没有被映射到物理内存中。直到对这块内存进行读写时，CPU才会真正为其分配物理内存；
3. 虚拟内存中连续的页面，在物理内存不一定是连续，只要维护好映射关系即可正常使用内存地址。这种映射关系是通过页表来实现；
4. 虚拟内存的地址空间和机器字宽有关，32位机器，指向内存的指针是32位，因此它的虚拟地址空间是2<sup>32</sup>，也就是4GB；64位机器，指向内存的指针是64位的，但实际只使用了低48位，因此它的虚拟地址空间是2<sup>48</sup>，也就是256T。

## 2.1.分段式

操作系统早期使用『内存分段』的方式管理虚拟内存和物理内存之间的映射。分段机制下的虚拟地址由两部分组成，**段选择子**和**段内偏移量**。

![](./images/分段式内存管理-1.jpeg)



- **段选择子**就保存在段寄存器里面。段选择子里面最重要的是**段号**，用作段表的索引。**段表**里面保存的是这个**段的基地址、段的界限和特权等级**等。
- 虚拟地址中的**段内偏移量**应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。 

![](./images/分段式内存管理-2.jpeg)

分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址：要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 = 7500。

【分段式的缺点】

- 产生大量的**内存碎片**
- **内存置换（swap）的效率低**

## 2.2.分页式

内存分段会出现内存碎片和内存交换太大的问题，要想解决这个问题，减小内存管理单元的大小即可，也就是内存分页：**分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。这样一个连续并且尺寸固定的内存空间，我们叫**页**（*Page*）。在 Linux 下，每一页的大小为 `4KB`。

分页机制下，虚拟地址分为两部分，**页号**和**页内偏移**。页号作为页表的索引，**页表**包含物理页每页所在**物理内存的基地址**，这个基地址与页内偏移的组合就形成了物理内存地址：

![](./images/分页式内存管理-1.jpeg)

对于一个内存地址转换，三个步骤：

- 把虚拟内存地址，切分成页号和偏移量；
- 根据页号，从页表里面，查询对应的物理页号；
- 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。

------

在实际场景中，如果只用一层分页，会导致页表非常庞大：32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2<sup>^</sup>12），那么就需要大约 100 万 （2<sup>^</sup>20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 `4MB` 的内存来存储页表。因此实际使用：多级页表，把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 `1024` 个页表（二级页表），每个表（二级页表）中包含 `1024` 个「页表项」，形成**二级分页**：

![](./images/分页式内存管理-2.jpeg)

此时内存转换步骤变为：

1. 确定页目录基址：每个CPU都有一个页目录寄存器，最高级页表的基地址存在这个寄存器。在X86上，这个寄存器是CR3，每次计算物理地址，MMU都会从CR3寄存器中取出页目录所在的物理地址
2. 定位页目录项（PDE，即上图的一级页号）：一个32位的虚拟地址可以拆成 10位、10位和12位三段。第1步找到的页目录表基址加上高10位的值乘以4，就是页目录项的位置。（页目录项是4字节，1024个页目录项组成一页，正好是 4 * 1024k = 4kb，而1024个页目录项需要10位编码，所以可以通过高10位找到对应PDE）
3. 定位页表项（PTE，即上图的二级页号）：第2步找到页目录项记录着页表的位置，CPU通过页目录项找到页表的位置后，再用中间10位计算页表中的偏移，可以定位该虚拟地址对应的页表项（PTE）。
4. 确定物理地址：第3步CPU定位到页表项，它存储着物理地址，也就能找到改虚拟地址对应的物理页。此时虚拟地址还剩下12位，刚好对应物理页的所有字节（一个物理页4kb = 4 * 1024b = 2<sup>^</sup>12b）因此可以用12位来表示业内偏移，直接通过物理页的地址加上虚拟地址的低12位。

------

对于64位系统，演变成4级目录：

- 全局页目录项 PGD（*Page Global Directory*）；
- 上层页目录项 PUD（*Page Upper Directory*）；
- 中间页目录项 PMD（*Page Middle Directory*）；
- 页表项 PTE（*Page Table Entry*）；

![](./images/分页式内存管理-3.jpeg)

# 3.内存布局

当程序保存在磁盘时，它的每一个单元结构被称为Section；当程序被加载到内存时，它的每一个单元结构被称为Segment。Segment会将具有相同权限属性的Section集映射到一起，为它们分配一块内存空间，因此往往多个Section对应一个Segment，例如：

- `.text`、`.rodata`等只读的Section，会映射到内存的「只读/执行」权限的Segment里；
- `.data`、`.bss`等可读写的Section，会映射到内存的「读写」权限的Segment里；
- `.symtab`、`.strtab`等磁盘二进制的一些辅助信息的Section，不会在内存中映射；

![](https://static001.geekbang.org/resource/image/bc/c9/bca1533a0af7ee8476yy12f4b04083c9.jpg?wh=2284x1319)

## 3.1.逻辑布局

![](https://static001.geekbang.org/resource/image/fc/c0/fcb6231d9cc3841643e4b84462e5b3c0.jpg?wh=2284x1980)

CPU运行一个程序，需要将存放在磁盘的进程文件载入内存，因此就会有进程的内存布局：

- 代码段：存储程序的机器码
- 数据段：在程序源代码中，对于有初值的变量，它的初始值会存放在程序的二进制文件。那么在加载这个程序的时候，这些数据也会被装载到内存中，即程序的数据段。因此，数据段存放的是程序中已经初始化且不为0的全局变量和静态变量
- BSS段：已经初始化的全局变量和静态变量会存放在「数据段 」，而对于未初始化的，编译器知道默认值都是0，所以不需要将其保存到二进制文件，进而就不需要加载到「数据段」，只需要记录它们的大小，此时就会存储到BSS段（全称是 Block Started by Symbol，也被记为 Better Save Space）
- 栈/堆：「数据段」和「BSS段」都会存储变量，主要是全局变量和静态变量。但在程序运行期间，还需要记录临时变量和运行时产生的变量，这些会被存储在「堆空间」和「栈空间」

以上是一个进程运行的基本内存布局，现代应用程序还会包含其它区域，主要是：

1. 存放加载的共享库的内存空间：如果一个进程依赖共享库，那对应的，该共享库的代码段、数据段、BSS 段也需要被加载到这个进程的地址空间中
2. 共享内存段：我们可以通过系统调用映射一块匿名区域作为共享内存，用来进行进程间通信
3. 内存映射文件：我们也可以将磁盘的文件映射到内存中，用来进行文件编辑或者是类似共享内存的方式进行进程通信

## 3.2.IA-32位

32位机器上，每个进程具有4GB的寻址能力，Linux默认将高地址的1GB空间分配给内核，剩余的低3GB是用户可以使用的用户空间

![](https://static001.geekbang.org/resource/image/61/b2/61ee74faa861797b34397ed837a027b2.jpg?wh=2284x1808)

## 3.3.Intel-64位

目前，Intel 64 处理器往往支持 48 位的虚拟地址，则寻址空间是 2^48，即 256TB。将低 128T 的空间划分为用户空间，高 128T 划分为内核空间：

![](https://static001.geekbang.org/resource/image/12/1c/1258dabe44e33c66c0f423d8d24a8f1c.jpg?wh=2284x1578)

# 4.栈

堆的空间有一个向下的箭头，标明栈地址空间的增长方向（栈地址是向低地址方向增长），每次进程再向内核申请新的栈地址时，其地址值是减少的。栈的指针叫做“Stack pointer”。

## 4.1.从指令的角度理解栈

调用一个函数，CPU会在栈空间开辟一块区域，该函数的局部变量都在这块区域存活，当函数执行完，这块区域就会被回收。这块区域被称为 stack frame，即栈帧。本质上，栈帧就是一个函数的活动记录。而当一个函数（A）调用另一个函数（B），会在A栈帧的下方创建函数B的栈帧（注意：栈是高地址向低地址增长的），等函数B执行完，回收栈帧B，又继续执行函数A。

```c
// 一个计算阶乘的函数
int fac(int n) {
    return n == 1 ? 1 : n * fac(n-1);
}
```

执行下面两行命令:

```bash
gcc -o fac fac.c
objdump -d fac
```

可以得到对应的汇编代码:

```assembly
40052d:       55                      push   %rbp
40052e:       48 89 e5                mov    %rsp,%rbp
400531:       48 83 ec 10             sub    $0x10,%rsp
400535:       89 7d fc                mov    %edi,-0x4(%rbp)
400538:       83 7d fc 01             cmpl   $0x1,-0x4(%rbp)
40053c:       74 13                   je     400551 <fac+0x24>
40053e:       8b 45 fc                mov    -0x4(%rbp),%eax
400541:       83 e8 01                sub    $0x1,%eax
400544:       89 c7                   mov    %eax,%edi
400546:       e8 e2 ff ff ff          callq  40052d <fac>
40054b:       0f af 45 fc             imul   -0x4(%rbp),%eax
40054f:       eb 05                   jmp    400556 <fac+0x29>
400551:       b8 01 00 00 00          mov    $0x1,%eax
400556:       c9                      leaveq
400557:       c3                      retq
```

- 第1行：当前栈基址存到栈顶；
- 第2行：将栈指针保存到栈基址寄存器；上面两行是将当前函数的栈帧创建在调用函数的栈帧下，同时保存调用者的栈基址便于恢复
- 第3行：把栈向下增长0x10，为了给局部变量预留空间。无限创建栈帧会出现StackOverflow，因为操作系统会在栈空间的尾部设置一个禁止读写的页，当栈增长到这里，操作系统会发出SIGSEGV信号，进程响应这个信号而中断执行；
- 第4行：把变量n存到栈上，变量 n 一开始是存储在寄存器 edi 中的，存储的目标地址是栈基址加上 0x4 的位置，也就是这个函数栈帧的第一个局部变量的位置；
- 第5行：将变量 n 与常量 0x1 进行比较；
- 第6行：如果比较的结果是相等的，那么程序就会跳转到 0x400551 位置继续执行。0x400551 是第 13 行，它把 0x1 送到寄存器 eax 中，然后返回，就是说当 n==1 时，返回值为 1；
- 第7,8,9行：若第6行比较结果不等，就不会跳转，继续执行7,8,9行，把 n-1 送到 edi 寄存器中，即以 n-1 为参数调用 fac 函数。调用的返回值在 eax 中，第 11 行会把返回值与变量 n 相乘，结果仍然存储在 eax 。然后程序就可以跳转到 0x400556 处结束这次调用；
- 第10行：执行 callq 指令时，CPU 会把 rip 寄存器中的内容，也就是 call 的下一条指令的地址放到栈上（在这个例子中就是 0x40054b），然后跳转到目标函数处执行。当目标函数执行完成后，会执行 ret 指令，这个指令会从栈上找到刚才存的那条指令，然后继续恢复执行。

## 4.2.栈切换

【执行单元】

执行单元：是指CPU调度和分派的基本单位，它是一个CPU能正常运行的基本单位。CPU可以将执行单元的当前状态保存，然后暂定执行单元的运行，后续将状态恢复就可以重新调度该执行单元。像这种保存状态、挂起、恢复执行、灰度状态的完整过程，称为执行单元的调度。常见的执行单元有：进程、线程和协程三种。

【协程】

协程是比线程更轻量的执行单元。进程和线程的调度是有操作系统负责，而协程的调度是由执行单元相互协商进行调度的，因此它的切换发生在用户态。只有前一个协程主动地执行yield函数，让出CPU的使用权，下一个协程才能得到调度。

【上下文切换】

执行单元的上下文切换，都是由栈这个核心结构支撑。栈切换的核心就是**栈指针 rsp 寄存器的切换，只要我们想办法把 rsp 切换了，就相当于换了执行单元的上下文环境**。

### 4.2.1.进程的调度和切换

进程的切换，可以参考下面的代码

```c
#include <unistd.h>
#include <stdio.h>

int main() {
    pid_t pid;
    if (!(pid = fork())) {
        printf("I am child process\n");
        exit(0);
    }
    else {
        printf("I am father process\n");
        wait(pid);
    }

    return 0;
}
```

fork 是一个系统调用，用于创建进程，如果其返回值为 0，则代表当前进程是子进程，如果其返回值不为 0，则代表当前进程是父进程，而这个返回值就是子进程的进程 ID。上面这段程序，最难理解的是第6行，为啥一次fork后，会有两种不同的返回值？

那是因为fork 方法本质上在系统里创建了两个栈，这两个栈一个是父进程的，一个是子进程的。创建的时候，子进程完全“继承”了父进程的所有数据，包括栈上的数据。父子进程栈的情况如图:

![](https://static001.geekbang.org/resource/image/05/bb/05f522cfcaa8ef2d79fa7221cc1bb8bb.jpg?wh=2284x1445)

只要有一个进程对栈进行修改，栈就会复制一份，然后父子进程各持有一份。上图的黄色部分也是进程共用的，如果有一个进程修改它，操作系统也会复制一份副本，这种机制叫做写时复制。

【如何切换呢？】

本质上，进程的切换，就是**CPU的rsp寄存器指向不同进程的栈**：

- 调度父进程：rsp这个栈指针指向父进程的栈，父进程的栈上是fork函数的frame，当CPU执行fork的ret语句时，返回值就是子进程的PID
- 调度子进程：rsp这个栈指针执行子进程的栈，子进程的栈上同样也是fork函数的frame，它也会执行一次fork的ret语句，只不过此时它的返回值为0。

### 4.2.2.用户态和内核态的切换

操作系统除了通过软中断（中断描述符表）进入内核态。实际上，内核态和用户态的切换也依赖于栈的切换，这个栈称为“内核栈”。它与用户应用程序使用的用户态栈是不同的。只有高权限的内核代码才能访问它。而内核态与用户态的相互切换，其中最重要的一个步骤就是两个栈的切换。

中断发生时，CPU 根据需要跳转的特权级，去一个特定的结构中，取得目标特权级所对应的 stack 段选择子和栈顶指针，并分别送入 ss 寄存器和 rsp 寄存器，这就完成了一次栈的切换。然后，IP 寄存器跳入中断服务程序开始执行，中断服务程序会把当前 CPU 中的所有寄存器，也就是程序的上下文都保存到栈上，这就意味着用户态的 CPU 状态其实是由中断服务程序在系统栈上进行维护的。如下图：

![](https://static001.geekbang.org/resource/image/e0/65/e015b6a3b4d93431194614e065078e65.jpg?wh=2284x2101)

当程序因为 call 指令或者 int 指令进行跳转的时候，只需要把下一条指令的地址放到栈上，供被调用者执行 ret 指令使用，这样可以便于返回到调用函数中继续执行。但图 4 中的内核态栈里有一点特殊之处，就是 **CPU 自动地将用户态栈的段选择子 ss3，和栈顶指针 rsp3 都放到内核态栈里**了。这里的数字 3 代表了 CPU 特权级，内核态是 0，用户态是 3。

中断结束时，中断服务程序会从内核栈里将 CPU 寄存器的值全部恢复，最后再执行"iret"指令（注意不是 ret，而是 iret，这表示是从中断服务程序中返回）。而 iret 指令就会将 ss3/rsp3 都弹出栈，并且将这个值分别送到 ss 和 rsp 寄存器中。这样就完成了从内核栈到用户栈的一次切换。同时，内核栈的 ss0 和 rsp0 也会被保存到上面说的一个特定的结构中，以供下次切换时使用。

# 5.堆

堆的空间有一个向上的箭头，标明堆地址空间的增长方向，每次进程再向内核申请新的堆地址时，其地址值是增大的。堆的指针叫做“Program break”

## 5.1.申请堆空间

不管是 32 位系统还是 64 位系统，内核都会维护一个变量 brk，指向堆的顶部，所以，brk 的位置实际上就决定了堆的大小。Linux系统提供了两个重要的系统调用来修改堆的大小，分别是sbrk和mmap。

【sbrk】

```c
#include <unistd.h>
void* sbrk(intptr_t incr);
```

sbrk函数通过给内核的brk变量增加`incr`以改变堆的大小，当`incr`为正数，堆增大；当`incr`为负数，堆减小。函数执行成功，返回brk变量的旧值；执行失败，返回-1，同时将errno设置为ENOMEM。

glibc是C的运行时库，它里面有两个用于内存管理的函数：malloc和free。malloc函数的基本原理是先向操作系统申请一块比较大的内存，再进行内存分配的优化。malloc函数向OS申请堆内存时，使用mmap以4k的整数倍一次申请多个页，这样可以使mmap区域以页对齐，页与页之间的排列整齐，从而避免内存碎片。

【mmap】

```c
#include <unistd.h>
#include <sys/mman.h>
/**
 * addr:   该内存区域的起始地址
 * length: 该内存区域的长度
 * prot:   该内存区域的访问权限
 * flags:  该内存区域的类型
 * fd:     文件描述符
 * offset: 文件内的偏移量
 */
void* mmap(void* addr, size_t length, int prot, int flags, int fd, off_t offset);
```

mmap的功能随之 prot、flags和fd这三个参数的不同，可以用于创建共享内存，可以创建磁盘文件映射区域，还可以用来申请堆内存。

- prot的值可以是以下四个常量的组合：
  - PROT_EXEC，表示这块内存区域有可执行权限，意味着这部分内存可以看成是代码段，它里面存储的往往是 CPU 可以执行的机器码；
  - PROT_READ，表示这块内存区域可读；
  - PROT_WRITE，表示这块内存区域可写；
  - PROT_NONE，表示这块内存区域的页面不能被访问；
- flags的值常量多（可以通过man mmap查看），以下是最重要的四种可取值常量：
  - MAP_SHARED，创建一个共享映射的区域，多个进程可以通过共享映射的方式，来共享同一个文件。这样一个进程对该文件的修改，其他进程也可以观察到，可以实现了数据的通讯；
  - MAP_PRIVATE，创建一个私有的映射区域，多个进程可以使用私有映射的方式，来映射同一个文件。但是，当一个进程对文件进行修改时，操作系统就会为它创建一个独立的副本，这样它对文件的修改，其他进程就看不到了，从而达到映射区域私有的目的；
  - MAP_ANONYMOUS，创建一个**匿名映射**，也就是没有关联文件。使用这个选项时，fd 参数必须为空。通常可以使用私有匿名映射来进行堆内存的分配。
  - MAP_FIXED，一般来说，addr 参数只是建议操作系统尽量以 addr 为起始地址进行内存映射，但如果操作系统判断 addr 作为起始地址不能满足长度或者权限要求时，就会另外再找其他适合的区域进行映射。如果 flags 的值取是 MAP_FIXED 的话，就不再把 addr 看成是建议了，而是将其视为强制要求。如果不能成功映射，就会返回空指针；
- fd的值只有两种类型：
  - 不为0，mmap映射的内存区域将会和文件关联；
  - 为0，没有对应的相关文件，此时就是匿名映射，flags 的取值必须为 MAP_ANONYMOUS；

![](https://static001.geekbang.org/resource/image/98/93/98fcb5aa607b8be9ffa037e9f7eea593.jpg?wh=2284x1285)

## 5.2.内存分配算法

高效得使用堆内存，需要对内存做『精细化管理』主要考虑两个因素：

1. 分配和回收的效率；
2. 内存区域的有效利用率。有效利用率又包含两方面：
   - 单块内存是否合理利用 →  内存浪费；
   - 内存块与块之间是否存在无法利用的小块内存 →  内存碎片；

### 5.2.1.空闲链表

人们用『链表』来对小块内存进行精细化管理，为了方便地进行分配和回收，把内存空闲区域记录到链表里，这就是空闲链表（free list）顾名思义，空闲链表的元素记录的就是未分配的内存，主要记录了内存的起始位置和长度：

![](https://static001.geekbang.org/resource/image/f4/e1/f43468e79fd311ca81d3e181d8575ae1.jpg?wh=2284x1147)

总长度为 100 的内存区域，已经分割成 16、16、20、16、16、16 六个小的内存块。其中带有颜色的内存块表示已经被分配出去（从左到右就是第1、3、5块）白色区域的内存块表示尚未分配。而空闲链表记录的就是这些白色区域的内存，每一块未分配的内存都会由一个空闲链表的节点管理，节点记录它的位置和长度。

### 5.2.2.简单算法

简单算法（Naive Algorithm）

- **分配**：遍历free list查找可用的内存空闲块，将内存块取下调整好参数再重新挂载到链表上，例如：要请求的大小是 m，就将这个结点从链表中取下，把起始位置向后移动 m，大小也相应的减小 m。将修改后的结点重新挂到链表。
- **释放**：将这块区域按照起始起址的排序放回到链表里，并且检查它的前后是否有空闲区域，如果有就合并成一个更大的空闲区。
- **缺点**：分配和释放会造成空闲区域不连续，会产生内存碎片，无法满足大块内存的分配<sup>1</sup>；其次，每次分配需要遍历free list，复杂度为O(n)，并发环境下需要加锁，导致分配效率一般且并发场景下性能恶化<sup>2</sup>。

### 5.2.3.分桶式内存管理

分桶式内存管理采用了多个链表，对于单个链表，它内部的所有节点对应的内存区域的大小是相同的。比如最常见的，是以 4 字节为最小单位，把所有 4 字节的区域挂到同一个链表上，再把 8 字节的区域挂到一起，然后是 16 字节，32 字节，以 2 次幂向上增长：

![](https://static001.geekbang.org/resource/image/cd/c2/cd9deb75706b6e5267e8f7f308c205c2.jpg?wh=2284x1222)

- **分配**：找到满足分配请求的最小区域，到对应链表里将整块区域取出来。例如：分配一个 7 字节的内存块，就可以从 8 字节大小的空闲链表里直接取出链表头上的那块区域，分配给应用程序。删除链表头的时间复杂度是O(1)，分配效率快。
- **释放**：把要释放的内存直接挂载到相应的链表里，复杂度也是O(1)，效率高。
- **缺陷**：区域内部的使用率不够高和动态扩展能力不够好：申请的内存大小是7，却只能分配8的块，会造成1字节的浪费；4字节的区域耗费完，但8字节的空闲区域还有，此时再要申请大小为4的内存，直接分配8的块也会造成内存浪费。

### 5.2.4.伙伴系统

为了解决分桶式内存管理的缺陷，人们在分桶的基础上继续改进，让内存可以根据需求动态地决定小的内存区域和大的内存区域的比例，即伙伴系统。

- **分配**：请求一块 4 字节大小的空间，在 4 字节的 free list 上找不到空闲区域，系统就会往上找，假如 8 字节和 16 字节的 free list 中也没有空闲区域，就会一直向上找到 32 字节的 free list。

  ![](https://static001.geekbang.org/resource/image/6f/26/6f9ef8402a8c0d1c9fdb61a3b4d24f26.jpg?wh=2284x1321)

  伙伴系统不会直接把 32 的空闲区域分配出去，它会先把 32 字节分成两个 16 字节，把后边一个挂入到 16 字节的 free list 中。然后继续拆分前一半。前一半继续拆成两个 8 字节，再把后一半挂入到 8 字节的 free list，最后，把前一半 8 字节拿去分配，当然这里也要继续拆分成两个 4 字节的空闲区域，其中一个用于本次 malloc 分配，另一个则挂入到 4 字节的 free list。分配后的内存的状态如下所示：

  ![](https://static001.geekbang.org/resource/image/68/fb/68e667bdf6yy507f21e0f2b775cd7dfb.jpg?wh=2284x1273)

- **释放**：被释放的内存相邻的那个伙伴也是空闲的，伙伴系统就会把它们合并成一个更大的连续内存

## 5.3.内存管理实现

### 5.3.1.malloc

glibc 中的 malloc 实现，采用了分桶的策略，但是它的每个桶里的内存不是固定大小的，而是采用了将 1 ~ 4 字节的块挂到第一个链表里，将 5 ~ 8 字节的块挂到第二个链表里，将 9~16 字节的块挂到第三个链表里，依次类推。

单个链表内部则采用 naive 的分配方式，比如要分配 5 个字节的内存块，会先在 5 ~ 8 这个链表里查找，如果查找到的内存大小是 8 字节的，那就会将这个区域分割成 5 字节和 3 字节两个部分，其中 5 字节用于分配，剩余的 3 字节的空闲区域则会挂载到 1~4 这个链表里

### 5.3.2.Tcmalloc

Google 公司实现的 Tcmalloc 库，相比起其他的 malloc 实现，最大的改进是在多线程的情况下性能提升。它引入了线程本地缓存 (Thread Local Cache)，每个线程在分配内存的时候都先在自己的本地缓存中寻找，如果找到就结束，找不到时才会继续向全局管理器申请一块大的空闲区域，然后按照伙伴系统的方式继续添加到本地缓存中去。

### 5.3.3.自定义实现



# 6.编译链接

代码无非是由函数和变量组成，每个变量和函数都有自己的名称，正常会把这些名称叫做“符号”。但是CPU执行程序代码时，它并不认识符号，只能理解内存地址。因此，需要有一个组件将程序中的符号转换成 CPU 执行时的内存地址，这个组件叫做“链接器”。可以分为三种情况：

1. 生成二进制可执行文件的过程中。这种情况称为静态链接；
2. 在二进制文件被加载进内存时。这种情况是在二进制文件保留符号，在加载时再把符号解析成真实的内存地址，这种被称为动态链接；
3. 在运行期间解析符号。这种情况会把符号的解析延迟到最后不得不做时才去做符号的解析，这也是动态链接的一种。

## 6.1.链接器工作流程

【链接器作用】

- 合并中间文件成可执行文件；
- 重定位。

------

【合并文件】

程序代码文件存在代码段和数据段等多个section，链接器需要对编译器生成的多个目标（.o）文件进行合并，一般采取的策略是相似段的合并，最终生成共享文件（.so）或者可执行文件。在这个阶段中，链接器会对输入的各个目标文件进行扫描，获取各个段的大小，并且同时会收集所有的符号定义以及引用信息，构建一个全局的符号表。当链接器构造好最终的文件布局以及虚拟内存布局后，根据符号表就可以确定每个符号的虚拟地址。

![](https://static001.geekbang.org/resource/image/e2/82/e22cc1820a1e9b5e3fc44b844dba7182.jpg?wh=2284x1301)

【重定位】

完成上一步后，链接器会对整个文件再进行第二遍扫描。这一阶段，会利用第一遍扫描得到的符号表信息，依次对文件中每个符号引用的地方进行地址替换，即对符号的解析以及冲定位过程。在GNU/Linux环境下，可以通过readelf和objdump两个工具：

- 对二进制文件进行反汇编会使用objdump工具；
- 用readelf工具解析二进制文件信息；

重定位执行流程的总结（详细的...看不懂汇编）：

1. 静态函数不需要重定位因为和执行单元代码都在.text段，相对位置在编译的时候就能确定了，因为链接器合并中间文件时相对位置不会变。
2. 静态变量需要重定位，因为和编译单元代码段.text分属不同的section，在.data，链接器合并文件时会重新排布，所以需要重定位。
3. 全局变量/函数，外部变量/函数都是需要被重定位的，大致方法就是： 编译器先用0占位符号、链接重定位表找符号、定位符号地址、然后在当前代码段计算RIP相对偏移位置填上。

## 6.2.静态链接

链接器将不同的编译单元生成的中间文件组合在一起，并且为各个编译单元中的变量和函数分配地址，然后将分配好的地址传给引用者，这个过程就是静态链接，它发生在**编译期间**。

静态链接最大的问题就是：无法共享。程序A和程序B都需要依赖C，采用静态链接，需要将C链接到A的二进制文件和B的二进制文件，导致系统运行A和B时，内存中会加载两份C的代码。

## 6.3.动态链接

动态链接的重定位发生在：**加载期间**、**运行期间**。将常用的公共的函数都放到一个文件中，在整个系统里只会被加载到内存中一次，无论有多少个进程使用它，这个文件在内存中只有一个副本，这种文件就是动态链接库文件。

在 Linux 里是共享目标文件（ share object, so)，在 windows 下是动态链接库文件 （dynamic linking library，dll）。

【特点】

1. 动态链接库文件的代码是地址无关的（它的实现依赖于地址无关代码）。
2. 不同模块之间符号的链接过程，推迟到加载期间再运行。

### 6.3.1.地址无关技术

动态库文件被加载进内存以后，在物理内存只有一份，多个进程都可以将它映射进自己的虚拟地址空间。各个进程在映射时可以将动态库的代码段映射到任意的位置。

![](https://static001.geekbang.org/resource/image/f3/b4/f372ba2fdae24f462c45fc4bfd8a3db4.jpg?wh=2284x1385)

但是，如果共享的动态库超过了两个，并且这些动态库之间还有相互引用。此时，进程 1 将 foo 方法映射到自己的虚拟地址 0x1000 处，而调用 foo 方法的指令被映射到 0x2000 处，那么 call 指令如果采用依赖 rip 寄存器的相对寻址的办法，这个偏移量应该填 -0x1000。进程 2 将 foo 方法映射到自己虚拟地址 0x2000 处，调用 foo 方法的指令被映射到 0x5000 处，那么 call 指令的参数就应该填 -0x3000。这就产生了冲突。

![](https://static001.geekbang.org/resource/image/ba/63/baa40c177b411856f1c2e1918bc2ef63.jpg?wh=2284x1261)

对于上面这种动态链接，基于rip 寄存器进行相对寻址的办法执行不了，相对寻址要求目标地址和本条指令的地址之间的相对值是固定的，这种代码就是地址有关的代码。当目标地址和调用者的地址之间的相对值不固定时，就需要地址无关代码技术。

在计算机科学领域，有一句名言：`计算机领域的所有问题都可以使用新加一层抽象来解决`。同样，要实现代码段的地址无关代码，思路也是通过添加一个中间层，使得对全局符号的访问由**直接访问**变成**间接访问**：

- 引入一个固定地址，让引用者与这个固定地址之间的相对偏移是固定的，然后这个地址处再填入 foo 函数真正的地址。这个地址位于数据段中，是每个**进程私有**的。这个新引入的固定地址就是全局偏移表 (Global Offset Table, GOT)

  ![](https://static001.geekbang.org/resource/image/e7/88/e790179942821d8c5acb02de69fb1b88.jpg?wh=2284x1307)

- call 指令处被填入了 0x3000，这是因为进程 1 的 GOT 与 call 指令之间的偏移是 0x5000-0x2000=0x3000，同时进程 2 的 GOT 与 call 指令之间的偏移是 0x8000-0x5000=0x3000。所以对于这一段共享代码，不管是进程 1 执行还是进程 2 执行，它们都能跳到自己的 GOT 表里。
- 然后，进程 1 通过访问自己的 GOT 表，查到 foo 函数的地址是 0x1000，它就能真正地调用到 foo 函数了。进程 2 访问自己的 GOT 表，查到 foo 函数的地址是 0x2000，它也能顺利地调用 foo 函数。这样就通过引入了 GOT 这个间接层，解决了 call 指令和 foo 函数定义之间的偏移不固定的问题。

这种技术就是地址无关代码 (Position Independent Code, PIC)

【GOT表项含义】

1. GOT.PLT[0]位置被加载器保留，它里面存放的是.dynamic 段的地址；
2. GOT.PLT[1]位置存放的是当前 so 的 ID，这个 ID 是加载器在加载当前动态库文件的时候分配的；
3. GOT.PLT[2]位置存放的是动态链接函数的入口地址，一般是动态链接器中的 _dl_runtime_resovle 函数。这个函数的作用是找到需要查找的符号地址，并最终回填到 GOT.PLT 表的对应位置

### 6.3.2.延迟绑定技术

为了避免加载期间就把GOT的符号全部解析并重定位，把函数地址的重定位工作一直推迟到第一次访问的时候再进行，这种就叫做：延迟绑定技术（Lazy binding）。hotspot虚拟机在执行类加载时使用的`patch code`就是一种延迟绑定的技术，它是在运行时修改指令；而为了降低风险，动态度的延迟绑定选择用GOT表实现。

把 GOT 中的待解析符号的地方都填成动态符号解析的函数，当 CPU 执行到这个函数，就会跳转进去解析符号，然后把 GOT 表的这一项填成符号的真正的地址；但是动态解析符号的函数 _dl_runtime_resolve 依赖两个参数，一个是当前动态库的 ID，另一个是待解析的符号在 GOT 表中的序号。为了解决参数传递的问题，动态链接引入了过程链接表（Procedure Linkage Table， PLT）将动态解析符号的过程变成了”三级跳“

![](https://static001.geekbang.org/resource/image/b6/02/b675cc80d4e8c10af17249d4e6461f02.jpg?wh=2284x1648)

在程序的代码段里（左侧）main函数对B函数的调用转成了对”B@plt“的调用（右下角）。B@plt的第一条指令是： jmp *(GOT[3])，是一个间接跳转，目标是GOT表偏移为0x18的位置。正常情况0x18这个位置应该就是B函数的真实地址，但是现在填入的是指向了"B@plt + 0x6 "的位置，这是为了传递参数给 _dl_runtime_resolve 函数。然后就开始了三级跳转：

1. 序号①，第一级跳转，它的目的是参数0入栈（GOT表的三个固定位置被占用，所以参数0就是代表0x18的位置，后面这里存放的就是B函数的真实地址）
2. 序号②，第二级跳转，它的目的是把动态库的ID压栈传参；
3. 序号③，第三级跳转，这次才真正地调用到了符号解析函数`_dl_runtime_resolve`，方法执行完后，B函数的真实地址就会被填入到GOT表中。

当执行完了重定位过程以后，CPU 再一次运行到 main 里的 call 指令时，就能通过一次跳转就调用到真正的 B 函数，如下图所示。重定位完以后，只有红色字体的代码和数据是起作用的，.plt 段里的其他代码就被“短路”掉了

![](https://static001.geekbang.org/resource/image/fb/11/fb2fb8ca742131711b040df30a452411.jpg?wh=2284x1742)

