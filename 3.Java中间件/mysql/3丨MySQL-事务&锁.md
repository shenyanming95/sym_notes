# 1.MySQL事务基础

## 1.1.事务概念

- **事务**：一组逻辑操作单元，使数据从一种状态变换到另一种状态；

- **事务处理(事务操作)**：当在一个事务执行多个操作时，要么所有的操作都被提交(commit)，则这些操作就永久地保存起来；要么数据库管理系统放弃所做的所有操作，整个事务回滚(rollback)到最初状态

## 1.2.ACID属性

事务具有以下4个属性，通常简称为事务的ACID属性：

- **原子性(**Atomicity)：事务是一个原子操作单元，其对数据的修改，要么全部  执行，要么全都不执行；
- **一致性**(Consistent)：在事务开始和完成时，数据都必须保持一致状态，所有数据规则都要应用于事务的修改，保持数据完整 ；
- **隔离性**(Isolation)：保证事务在不受外部并发操作影响的“独立”环境执行，  这意味事务处理过程中的中间状态对外部是不可见的，即  并发执行的各个事务之间是不能相互干扰的；
- **持久性**(Durable)：事务完成之后，它对于数据的修改是永久性的，即使出现  系统故障也能够保持。

## 1.3.事务并发处理 

### 1.3.1.并发问题

<table>
  <tr>
  	<th>问题</th>
    <th>描述</th>
  </tr>
  <tr>
  	<td width='20%'>更新丢失</td>
    <td>当两个或多个事务选择同一张表的同一行更新数据，由于每个事务不知道其他事务的存在，就会发生丢失更新问题—最后的更新覆盖其他事务所做的更新</td>
  </tr>
  <tr>
  	<td>脏读</td>
    <td>一个事务正在对一条记录做修改，在这个事务未commit之前，另一个事务也来读取同一条记录，这时第二个事务就有可能读取到这些"脏"数据，因为未提交之前，所做的数据修改可能是测试，也可能是错误的数据，这种现象叫做“脏读”</td>
  </tr>
  <tr>
  	<td>不可重复读</td>
    <td>一个事务范围内两个相同的查询却返回了不同数据，也就是说一个事务在读取某些数据后的某个时间（事务未完成），再次读取以前读过的数据，由于其它事务更新了该字段导致读出的数据已经发生了改变，或某些记录已经被删除了，这种现象就叫做"不可重复读"</td>
  </tr>
  <tr>
  	<td>幻读</td>
    <td>一个事务按相同的查询条件重新读取以前读取的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”</td>
  </tr>
</table>
幻读和脏读有点类似：

- 脏读是事务B读取事务A修改中的数据

- 幻读是事务B读取事务A新增的数据

### 1.3.2.事务隔离级别

一个事务去其它事务隔离的程度就称为：隔离级别。数据库规定了多种事务隔离级别，不同隔离级别对应不同的干扰程度，隔离级别越高，数据一致性越好，但是并发性越弱。数据库提供4种事务隔离级别:

<table>
  <tr>
  	<th>隔离级别</th>
    <th>描述</th>
  </tr>
  <tr>
  	<td width='33%'>未提交读<br/>(Read cuncommited)</td>
    <td>允许事务读取未被其它事务提交的操作数据。脏读、不可重复度和幻读又会发生</td>
  </tr>
  <tr>
  	<td>已提交读<br/>(Read commited)</td>
    <td>只允许事务读取已被其它事务提交的操作，可以避免脏读，但无法解决不可重复读和幻读</td>
  </tr>
  <tr>
  	<td>可重复读<br/>(Repeatable read)</td>
    <td>确保事务可以多次从一个字段中读取相同的值，在这个事务持续期间，禁止其它事务对这个字段进行更新。可以避免脏读和不可重复读，但幻读仍然存在</td>
  </tr>
  <tr>
  	<td>串行化<br/>(Serializable)</td>
    <td>确保事务可以从一个表中读取相同的行，在这个事务持续期间，禁止其它事务对该表执行插入符。更新和删除操作，所有并发问题都可以避免，但性能十分低</td>
  </tr>
</table>

数据库的事务隔离越严格，并发副作用越小，但付出的代价也就越大，因为事务隔离实质上就是使事务在一定程度上“串行化”进行，显然与“并发”是矛盾的。mysql默认是可重复读级别，即解决了脏读和不可重复读。查看当前数据库的事务隔离级别：

```sql
show variables like 'tx_isolation';
```

# 2.MySQL事务实现

## 2.1.持久性实现

MySQL通过undo和redo日志来保证自己崩溃下数据一致性：

1. **时刻A**（刚在内存中更改完数据页，还没有开始写redo log的时候奔溃）：

   因为内存中的脏页还没刷盘，也没有写redo log和binlog，即这个事务还没有开始提交，所以奔溃恢复跟该事务没有关系；

2. **时刻B**（正在写redo log或者已经写完redo log并且落盘后，处于prepare状态，还没有开始写binlog的时候奔溃）：

   恢复后会判断redo log的事务是不是完整的，如果不是则根据undo log回滚；如果是完整的并且是prepare状态，则进一步判断对应的事务binlog是不是完整的，如果不完整则一样根据undo log进行回滚；

3. **时刻C**（正在写binlog或者已经写完binlog并且落盘了，还没有开始commit redo log的时候奔溃）：

   恢复后会跟时刻B一样，先检查redo log中是完整并且处于prepare状态的事务，然后判断对应的事务binlog是不是完整的，如果不完整则一样根据undo log回滚，完整则重新commit redo log；

4. **时刻D**（正在commit redo log或者事务已经提交完的时候，还没有反馈成功给客户端的时候奔溃）：

   恢复后跟时刻C基本一样，都会对照redo log和binlog的事务完整性，来确认是回滚还是重新提交。

## 2.2.隔离性实现

在MySQL里，有两个“视图”的概念：

- 一个是view。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view … ，而它的查询方法与表一样。
- 另一个是InnoDB在实现MVCC时用到的一致性读视图，即consistent read view，用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现。

其中，第二个视图，就是基于 undo log 日志实现的，在可重复读隔离级别下，事务在启动的时候就“拍了个快照”，这个快照是针对整个库。InnoDB里面每个事务有一个唯一的事务ID，叫作transaction id。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的；每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把transaction id赋值给这个数据版本的事务ID，记为row trx_id，一个记录被多个事务连续更新后的状态：MySQL中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。

当前值是4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的read-view。如图中看到的，在视图A、B、C里面，这一个记录的值分别是1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于read-view A，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。同时你会发现，即使现在有另外一个事务正在将4改成5，这个事务跟read-view A、B、C对应的事务是不会冲突的。

![](./images/行状态变更.png)

上图是同一行数据的4个版本，当前最新版本是V4，k的值是22，它是被transaction id 为25的事务更新的，因此它的row trx_id也是25。上图的三个虚线箭头（U1、U2、U3）就是undo log；而V1、V2、V3并不是物理上真实存在的，而是每次需要的时候根据当前版本和undo log计算出来的。比如，需要V2的时候，就是通过V4依次执行U3、U2算出来。**InnoDB利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。**

一个事务中读取数据，都是从这个快照中读取，数据被修改过，但是事务A不论在什么时候查询，看到这行数据的结果都是一致的，所以我们称之为一致性读；但是一旦涉及更新数据（select语句如果加锁，也是当前读），**都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。**一旦两个事务对同一行数据执行当前读时，必定会加锁，只能等待另一个事务释放这个锁，才能继续它的当前读

# 3.MySQL锁基础

MySQL有三种锁的级别：页级、表级、行级。MyISAM存储引擎采用的是表级锁（table-level locking）；BDB存储引擎采用的是页面锁（page-levellocking），也支持表级锁；InnoDB存储引擎既支持行级锁（row-level locking），也支持表级锁，默认行锁。MySQL这3种锁的特性可大致归纳如下：

- 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低

- 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度最高

- 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般

## 3.1.表锁

表锁：把整张表锁起来，分为读锁和写锁。表锁偏读，主要存在MyISAM引擎上

### 3.1.1.表读锁

当某个会话session为某个表table加了读锁，当前会话可以读表，不可以写表，还不可以读其他表，直至解锁；其他会话可以读表，不可以写表，还可以读其他表

- show open tables；查看Mysql表的加锁情况，In_use=0表示该表没有加任何锁

![](./images/表锁-读锁_1.png)

- lock table 【表名1】 【read/write】,【表名2】 【read/write】...;为表加锁

  ![](./images/表锁-读锁_2.png)

- unlock tables;解锁

### 3.1.2.表写锁

当会话session_1为表t_stu加了写锁：

session_1可以读表，可以修改表，不可以读/写其他未加锁的表

session_2不可以读表，不可以修改表，可以读/写其他未加锁的表

## 3.2.行锁

偏向InnoDB存储引擎，开销大，加锁慢，会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。InnoDB与MyISAM的最大不同有两点：一是支持事务，二是采用行级锁。行锁默认是就是开启的，只要修改数据表的某行数据，该行就会自动加行锁，不同的行有不同的锁，互不影响。当要测试行锁时，需要把Mysql的自动事务提交关了，否则一回车，事务就提交，无法测试。执行SQL:

```sql
set autocommit=0;
```

**一旦索引失效，行锁直接变成表锁**！！！

### 3.2.1.行锁分析

查看Mysql行锁的情况：

```sql
show status like'innodb_row_lock%';
```

<img src="./images/分析行锁.png" style="zoom:80%;" />

对各个状态量的说明如下：（单位是毫秒）

- innodb_row_lock_current_waits：当前正在等待锁定的数量

- innodb_row_lock_time：从系统启动到现在锁定总时间长度

- innodb_row_lock_time_avg：每次等待所花平均时间

- innodb_row_lock_time_max：从系统启动到现在等待最长一次所花的时间

- innodb_row_lock_waits：系统启动后到现在总共等待的次数

对于5个状态量，比较重要的是：

- innodb_row_lock_time_avg：等待平均时长

- innodb_row_lock_waits：等待总次数

- innodb_row_lock_time：等待总时长

尤其当等待次数很高，且每次等待时长也不小的时候，便要分析并制定优化计划

## 3.3.间隙锁

【什么是间隙锁】

当使用范围条件而不是相等条件检索数据时，并请求共享或排他锁，InnoDB会给符合条件的已存在记录的索引项加锁，对于键值在条件范围内但并不存在的记录，叫做“间隙”(GAP)，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）

【危害】

因为Query执行过程中若用范围查找，它会锁定整个范围内所有的索引键值，即使这个键值不存在。因此，间隙锁有一个比较致命的弱点，就是当锁定一个范围键值之后，就算某些不存在的键值也会被无辜锁定，而造成在锁定的时候无法插入锁定键值范围内的任何数据，仅当事务提交后才可添加，影响性能。

## 3.4.死锁

当出现死锁以后，有两种策略：

- 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置，默认值是50s
- 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。